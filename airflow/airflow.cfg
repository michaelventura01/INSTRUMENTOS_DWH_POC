[core]
# Definición de la conexión a la base de datos
sql_alchemy_conn = postgresql+psycopg2://admin:admin@postgres:5432/INSTRUMENTOS_DWH
# El ejecutor que Airflow utilizará (puede ser LocalExecutor, CeleryExecutor, etc.)
executor = LocalExecutor
# Directorio para almacenar los archivos de los DAGs
dags_folder = /opt/airflow/dags
# Directorio donde se almacenarán los logs
base_log_folder = /opt/airflow/logs
# El nivel de logging
logging_level = INFO

[webserver]
# Configuración para el servidor web de Airflow
# La IP y el puerto donde escuchará el servidor web
web_server_host = 0.0.0.0
web_server_port = 8080
# Clave secreta para el servidor web de Airflow (para seguridad)
secret_key = some-random-secret-key
# Número de workers para el servidor web
workers = 4

[scheduler]
# Configuración para el scheduler
# Frecuencia con la que se ejecuta el scheduler (en segundos)
scheduler_task_queued_timeout = 600
scheduler_task_queued_start_timeout = 120

[logging]
# Configuración para el logging
# Ubicación de los archivos de logs
remote_logging = False

[slack]
# Configuración para el slack si lo utilizas
slack_webhook_token = your_slack_webhook_token

[metrics]
# Opciones para monitorización y métricas
statsd_on = False